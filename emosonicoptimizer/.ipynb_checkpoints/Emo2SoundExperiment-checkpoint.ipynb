{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion-to-Sound Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import ipywidgets as widgets\n",
    "from functools import partial\n",
    "from IPython.display import display\n",
    "import pandas, imp, OSC, threading\n",
    "import pickle, time,socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait for SC to start...\n",
      "resume: establish OSC interfaces...\n",
      " []\n",
      " []\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "# first: select sound model \n",
    "#soundmodel = 'abstract'\n",
    "soundmodel = 'vocal'\n",
    "if (soundmodel == 'abstract'):\n",
    "    portMax = 9000\n",
    "else: portMax = 9001\n",
    "    \n",
    "sonmod = imp.load_source('sonmod', 'EmoSonics-soundmodels.py')\n",
    "print \"wait for SC to start...\"\n",
    "time.sleep(5); # wait until SC is started...\n",
    "print \"resume: establish OSC interfaces...\"\n",
    "\"\"\"\n",
    "To run vocal model: 1. make sure the path in EmoSonics-soundmodels.py has the correct path point at the sclang. \n",
    "                    2. make sure vowel is installed in Quark\n",
    "To run abstract mode: Make sure the Max program AbstractModel is in the same folder\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Setup the OSC model here. \n",
    "\"\"\"\n",
    "\n",
    "clientSC  = OSC.OSCClient(); clientSC.connect((\"127.0.0.1\", 57110)) # SC uses 57110 by default. \n",
    "\n",
    "def sc_msg(onset, msgAdr=\"/s_new\", msgargs=[\"s1\", 2000, 1, 0, \"freq\", 300, \"amp\", 0.5]):\n",
    "    global clientSC\n",
    "    bundle = OSC.OSCBundle()\n",
    "    msg = OSC.OSCMessage()\n",
    "    print msg\n",
    "    msg.setAddress(msgAdr)\n",
    "    msg.extend(msgargs)\n",
    "    bundle.append(msg)\n",
    "    bundle.setTimeTag(onset)\n",
    "    clientSC.send(bundle)\n",
    "\n",
    "\n",
    "clientMAX = OSC.OSCClient(); clientMAX.connect((\"127.0.0.1\", portMax)) \n",
    "def max_msg(onset, msgAdr=\"/s_new\", msgargs=[\"freq\", 300, \"amp\", 0.5]):\n",
    "    global clientMAX\n",
    "    bundle = OSC.OSCBundle()\n",
    "    msg = OSC.OSCMessage()\n",
    "    msg.setAddress(msgAdr)\n",
    "    msg.extend(msgargs)\n",
    "    bundle.append(msg)\n",
    "    bundle.setTimeTag(onset)\n",
    "    clientMAX.send(bundle)\n",
    "    \n",
    "if (soundmodel == \"vocal\") :    \n",
    "    sc_msg(0, \"/s_new\", [\"reverb\", 1001, 1, 0, \"outbus\", 0, \"room\", 0.4, \"mix\", 0.1, \"damp\", 0.8]);\n",
    "else: pass  \n",
    "# Test sound. \n",
    "if (soundmodel == \"vocal\") :\n",
    "    # use test tone to check if the reverb is one\n",
    "    sc_msg(0, \"/s_new\", [\"default\", 1002, 1, 1]); now = time.time(); \n",
    "    sc_msg(now+0.5, \"/n_free\", [1002])\n",
    "else: pass\n",
    "\n",
    "\"\"\"\n",
    "Mapping here needs some rework. \n",
    "\"\"\"\n",
    "# TH: for vocal synth\n",
    "parspec_vocal = array([ # name, min, max, scaling (lin/exp), default\n",
    "#(\"evrate\", 0.2, 4, \"exp\", 0.5, \"Hz\"),\n",
    "#(\"irregularity\", 0, 1, \"lin\", 0, \"%\"),\n",
    "(\"dur\", 0.005, 1.5, \"exp\", 0.4, \"secs\"), \n",
    "(\"att\", 0.001, 0.5, \"exp\", 0.001, \"secs\"),\n",
    "(\"decslope\", -50, 10, \"lin\", -12, \"dB/rm time\"),\n",
    "(\"amint\",  0, 1, \"lin\", 0, \"intensity\"),\n",
    "(\"amfreq\", 1, 50, \"exp\", 1, \"Hz\"),\n",
    "(\"pitch\", 20, 85, \"lin\", 50, \"midinote\"),\n",
    "(\"chirp\", -36, 36, \"lin\", 0, \"semitones/dur\"),\n",
    "(\"lfnfrq\", 5, 50, \"exp\", 5, \"Hz\"),\n",
    "(\"lfnint\", 0, 0.5, \"lin\", 0, \"rel. pitch\"),\n",
    "(\"vowel\", 0, 4, \"lin\", 2.5, \"uoaei\"),\n",
    "(\"voweldiff\", -2.5, 2.5, \"lin\", 0, \"delta\"),\n",
    "(\"bright\", 0.2, 1, \"lin\", 0.5, \"arb.u.\")], dtype=[\n",
    "      ('name', 'S20'), ('min', '>f4'), ('max', '>f4'), ('scaling', 'S10'), ('default', '>f4'), ('unit', 'S20')])\n",
    "\n",
    "# JJ: New parspec\n",
    "parspec_abstract = array([ # name, min, max, scaling (lin/exp), default\n",
    "#(\"evrate\", 0.2, 4, \"exp\", 0.5, \"Hz\"),\n",
    "#(\"irregularity\", 0, 1, \"lin\", 0, \"%\"),\n",
    "(\"dur\", 0., 1., \"lin\", 0.5, \"secs\"),\n",
    "(\"att\", 0., 1., \"lin\", 0.3, \"%\"),\n",
    "(\"desvol\", 0., 1., \"lin\", 0.5, \"dB/dur\"),\n",
    "(\"pitch\", 0, 1., \"lin\", 0.5, \"Hz\"),\n",
    "(\"chirp\", 0., 1., \"lin\", 0.5, \"semitones/dur\"),\n",
    "(\"lfndepth\", 0., 1., \"lin\", 0., \"rate\"),\n",
    "(\"lfnfreq\", 0, 1., \"lin\", 0., \"Hz\"),\n",
    "(\"amdepth\", 0., 1., \"lin\", 0., \"rate\"),\n",
    "(\"amfreq\", 0., 1., \"lin\", 0., \"Hz\"),\n",
    "(\"richness\", 0., 1., \"lin\", 0.5, \"%\"),\n",
    "(\"lpfreq\", 0., 1., \"lin\", 0.5, \"Hz\")  # I wonder if this is important.       \n",
    "    ], dtype=[\n",
    "      ('name', 'S20'), ('min', '>f4'), ('max', '>f4'), ('scaling', 'S10'), ('default', '>f4'), ('unit', 'S20')])\n",
    "\n",
    "\"\"\"\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "All the GUI functions:\n",
    "\"\"\"\n",
    "def parmap(par=(\"pitch\", 20, 85, \"lin\", 50, \"midinote\"), val=0.5):\n",
    "    mi, ma = par[1], par[2]\n",
    "    if(par[3]==\"lin\"): return mi+(ma-mi)*val\n",
    "    if(par[3]==\"exp\"): return mi*exp(log(ma/mi)*val)\n",
    "\n",
    "def parunmap(par=(\"pitch\", 20, 85, \"lin\", 50, \"midinote\"), val=40):\n",
    "    mi, ma = par[1], par[2]\n",
    "    if(par[3]==\"lin\"): return (val-mi)/(ma-mi)\n",
    "    if(par[3]==\"exp\"): return log(val/mi)/log(ma/mi)\n",
    "    \n",
    "def parvecmap(parspec, vec):\n",
    "    return array([parmap(parspec[k], v) for k,v in enumerate(vec)])\n",
    "\n",
    "def parvecunmap(parspec, vec):\n",
    "    return array([parunmap(parspec[k], v) for k,v in enumerate(vec)])    \n",
    "\n",
    "# test code:\n",
    "# print parvecunmap(parspec_vocal, parspec['default']) # get default parameters\n",
    "\n",
    "def playevent(soundmodel, v):\n",
    "    # v is unmapped vector, i.e. vector elements in [0,1]\n",
    "    if(soundmodel=='vocal'):\n",
    "        ps = parspec_vocal\n",
    "        vec = parvecmap(ps, v);\n",
    "        sc_msg(0, \"/s_new\", [\"jj1\", 1002+random.randint(900), 1,1] + \n",
    "           [x for pair in zip(ps['name'].tolist(), vec) for x in pair] );\n",
    "    if(soundmodel=='abstract'):\n",
    "        ps = parspec_abstract\n",
    "        vec = parvecmap(ps, v);\n",
    "        max_msg(0, \"/s_new\" , [x for pair in zip(ps['name'].tolist(), vec) for x in pair] )\n",
    "        \n",
    "    if(soundmodel=='physiological'):\n",
    "        ps = parspec_physiological\n",
    "        vec = parvecmap(ps, v);\n",
    "        max_msg(0, \"/s_new\" , [x for pair in zip(ps['name'].tolist(), vec) for x in pair] )\n",
    "        \n",
    "\n",
    "def mutate(parent, sigma=0.1):\n",
    "    d=size(parent)\n",
    "    child = clip((parent + sigma*random.randn(d)), 0, 1)\n",
    "    return child\n",
    "\n",
    "def create_next_generation(parentvec, sigma, nr_of_children=4):\n",
    "    global generation_counter, v\n",
    "    generation_counter += 1\n",
    "    return [parentvec] + [mutate(parentvec, sigma) for k in range(nr_of_children)]\n",
    "\n",
    "def append_data(dataset, time, target, generation_counter, logsigma, parvec, submit=0, userid=-1, sound=\"vocal\", run=-1):\n",
    "    dataset.append([userid, sound, run, time, target, generation_counter, logsigma, parvec, submit])    \n",
    "\n",
    "def savedata(dataset, prefix=\"user-soundmodel-run-\"):\n",
    "    df = pandas.DataFrame(data, columns=['uid', 'snd', 'run', 'time','target','generation','logsigma','parvec','submit'])\n",
    "    df.to_csv(prefix + time.strftime(\"-%Y%m%d-%H%M%S\") + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"fake\"\n",
    "userid = 1010\n",
    "# soundmodel = \"abstract\"\n",
    "run = 1\n",
    "log_sigma_initval = -0.8\n",
    "log_sigma_step = -0.2\n",
    "\n",
    "data = []  # time, target state, generation_counter, sigma, parvec\n",
    "generation_counter = 0\n",
    "v = []\n",
    "target_set_time = time.time()\n",
    "\n",
    "wlogsigma = widgets.FloatSlider(value=-0.5, min=-5, max=0, step=0.01, description='log(sigma):')\n",
    "\n",
    "def reset_settings():\n",
    "    global wtarget, generation_counter, v, wlogsigma, soundmodel\n",
    "    generation_counter = 0\n",
    "    target_set_time = time.time()\n",
    "    if(soundmodel=='vocal'):    \n",
    "        ps = parspec_vocal\n",
    "    elif(soundmodel=='abstract'): \n",
    "        ps = parspec_abstract\n",
    "    elif (soundmodel == 'physiological'): \n",
    "        ps = parspec_physiological\n",
    "    v = create_next_generation(parvecunmap(ps, ps['default']), 0.25)\n",
    "    wlogsigma.value = log_sigma_initval\n",
    "    \n",
    "reset_settings()\n",
    "\n",
    "wtarget = widgets.ToggleButtons(\n",
    "    description='select target',\n",
    "    options=['happy', 'surprised', 'angry', 'disgusted', 'sad', 'calm'])\n",
    "\n",
    "def target_on_value_change(change):\n",
    "    global generation_counter, target_set_time\n",
    "    generation_counter = 0\n",
    "    target_set_time = time.time()\n",
    "\n",
    "wtarget.observe(target_on_value_change, names='value')  \n",
    "\n",
    "w = widgets.ToggleButtons(\n",
    "    description='Choose best variation:',\n",
    "    options=['0', '1', '2', '3', '4'])\n",
    "\n",
    "def nextgenclick(arg):\n",
    "    global v, w, wlogsigma\n",
    "    parent = int(w.value)\n",
    "    append_data(data, time.time()-target_set_time, wtarget.value, generation_counter, \n",
    "                wlogsigma.value, v[parent].tolist(), userid=userid, sound=soundmodel, run=run)\n",
    "    v = create_next_generation(v[parent], exp(wlogsigma.value))\n",
    "    wlogsigma.value += log_sigma_step\n",
    "    w.value = '0'\n",
    "    \n",
    "wbutnext = widgets.Button(description='proceed')\n",
    "wbutnext.on_click(nextgenclick)\n",
    "\n",
    "wbutsubmit = widgets.Button(description='accept')\n",
    "\n",
    "def submit_choice(arg):\n",
    "    global w, v, wlogsigma\n",
    "    choice = int(w.value)\n",
    "    print \"submit\", wtarget.value, choice\n",
    "    append_data(data, time.time() - target_set_time, wtarget.value, generation_counter, \n",
    "                wlogsigma.value, v[choice].tolist(), submit=1, userid=userid, sound=soundmodel, run=run)\n",
    "    reset_settings()\n",
    "    w.value = '0'\n",
    "    targetidx = wtarget.options.index(wtarget.value)\n",
    "    #print targetidx, len(wtarget.options)\n",
    "    if(targetidx < len(wtarget.options)-1):\n",
    "        wtarget.value = wtarget.options[targetidx+1]\n",
    "    else:\n",
    "        print \"completed. thanks.\"\n",
    "        fname = \"../data/%s-%s-run%d\" % (username, soundmodel, run)\n",
    "        savedata(data, fname)\n",
    "        print \"data saved to\"+fname \n",
    "    \n",
    "wbutsubmit.on_click(submit_choice)\n",
    "display(wtarget, w, wbutnext, wlogsigma, wbutsubmit)\n",
    "def on_value_change(change):\n",
    "    global v, wlogsigma\n",
    "    id = int(change['new'])\n",
    "    print \"play \"\n",
    "    playevent(soundmodel, v[id])  \n",
    "w.observe(on_value_change, names='value')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = \"fake\"\n",
    "userid = 1010\n",
    "soundmodel = \"abstract\"\n",
    "run = 1\n",
    "log_sigma_initval = -1.0\n",
    "log_sigma_step = -0.2\n",
    "data = []  # time, target state, generation_counter, sigma, parvec\n",
    "generation_counter = 0\n",
    "v = []\n",
    "target_set_time = time.time()\n",
    "targetlist = ['happy', 'surprised', 'angry', 'afraid', 'neutral', 'disgusted', \n",
    "              'sad', 'tired', 'calm'];\n",
    "currentEmotion = 0 # use it to loop through targetlist\n",
    "degreelist = ['0', '1', '2', '3','4']\n",
    "class Rating_receiver:\n",
    "    def __init__(self, ip = '192.168.0.3', port = 8022, num_emotion = 9, num_degree = 4):\n",
    "        self.receive_address = ip, port\n",
    "        self.num_emotion = num_emotion\n",
    "        self.num_degree = num_degree\n",
    "        self.choice = targetlist[0]\n",
    "        self.degree = degreelist[0]\n",
    "        self.logValue = -1.0\n",
    "        self.count = 0\n",
    "        \n",
    "    def reset_settings(self):\n",
    "        global generation_counter, v,  soundmodel\n",
    "        generation_counter = 0\n",
    "        target_set_time = time.time()\n",
    "        if(soundmodel=='vocal'):    ps = parspec_vocal\n",
    "        if(soundmodel=='abstract'): ps = parspec_abstract\n",
    "        if (soundmodel == 'physiological'): ps = parspec_physiological\n",
    "        v = create_next_generation(parvecunmap(ps, ps['default']), 0.25)\n",
    "    def spawn(self):\n",
    "        print\"Server Created.\"\n",
    "        self.receiveServer = OSC.OSCServer(self.receive_address)\n",
    "        print self.receive_address# create a serve to receive OSC from the tablet\n",
    "        self.receiveServer.addDefaultHandlers()\n",
    "        print self.receiveServer\n",
    "        print self.receiveServer.address()\n",
    "        \n",
    "    def initilisation_handler(self, addr, tags, stuff, source):\n",
    "        print \"inside init\"\n",
    "        print stuff\n",
    "        print addr\n",
    "        print source\n",
    "        print tags\n",
    "        '''global userid, username, run\n",
    "        userid = stuff[1]\n",
    "        username = stuff[2]\n",
    "        #run = int(stuff[4])\n",
    "        \n",
    "        #print userid,username,run,stuff\n",
    "        \n",
    "'''\n",
    "    def emotion_handler(self, addr, tags, stuff, source):\n",
    "        self.choice = targetlist[stuff[0]]\n",
    "        print self.choice\n",
    "\n",
    "    def degree_handler(self, addr, tags, stuff, source):\n",
    "        self.degree = degreelist[stuff[0]]\n",
    "\n",
    "    def log_handler(self, addr, tags, stuff, source):\n",
    "        self.logValue = stuff[0]\n",
    "        print self.logValue\n",
    "\n",
    "    def proceed_handler(self, addr, tags, stuff, source):\n",
    "        global v, sm, currentEmotion\n",
    "        print \"next sound\";\n",
    "        currentEmotion =  stuff[0]\n",
    "#         playevent(soundmodel, v[id]) \n",
    "        \n",
    "    def accept_handler(self, addr, tags, stuff, source):        \n",
    "        global w, v, wlogsigma\n",
    "        \n",
    "        print \"submit\", self.choice,self.degree\n",
    "        append_data(data, time.time() - target_set_time, self.choice, generation_counter, \n",
    "                self.logValue, v[self.choice].tolist(), submit=1, userid=userid, sound=soundmodel, run=run)\n",
    "    #reset_settings()\n",
    "    #w.value = '0'\n",
    "    #targetidx = wtarget.options.index(wtarget.value)\n",
    "    #print targetidx, len(wtarget.options)\n",
    "    #if(targetidx < len(wtarget.options)-1):\n",
    "     #   wtarget.value = wtarget.options[targetidx+1]\n",
    "    #else:\n",
    "     #   print \"completed. thanks.\"\n",
    "#   fname = \"../data/%s-%s-run%d\" % (username, soundmodel, run)\n",
    "     #savedata(data, fname)\n",
    "# #  print \"data saved to\"+fname \n",
    "    \n",
    "    def save_handler(self, addr, tags, stuff, source):\n",
    "        global data, un, run\n",
    "        print \"completed. thanks.\"\n",
    "        fname = \"../data/%s-%s-run%d\" % (un, sm, run) # All 3 needs to be replaced. \n",
    "        #         savedata(data, fname)\n",
    "        df = pandas.DataFrame(data, \n",
    "            columns=['uid', 'snd', 'run', 'step', 'time', 'parvec', 'emotion', 'intensity'])\n",
    "        df.to_csv(fname + time.strftime(\"-%Y%m%d-%H%M%S\") + \".csv\", index=False)\n",
    "        data.append([userid.value, sm, run, \n",
    "                     self.count, time.time()-start_time, v, \n",
    "                     self.choice, self.degree])\n",
    "        print \"data saved to \" + fname\n",
    "        print \"Please inform the operator.\"\n",
    "        self.count = 0 # Reset counter. \n",
    "\n",
    "    \n",
    "    def add_handler(self):\n",
    "        self.receiveServer.addMsgHandler(\"/play\", self.accept_handler)\n",
    "        self.receiveServer.addMsgHandler(\"/next\", self.proceed_handler)\n",
    "        self.receiveServer.addMsgHandler(\"/emo\", self.emotion_handler)\n",
    "        self.receiveServer.addMsgHandler(\"/degree\", self.degree_handler)\n",
    "        self.receiveServer.addMsgHandler(\"/save\", self.save_handler)\n",
    "        self.receiveServer.addMsgHandler(\"/init\", self.initilisation_handler)\n",
    "        self.receiveServer.addMsgHandler(\"/logChange\", self.log_handler)\n",
    "            \n",
    "    def print_registered_func(self):\n",
    "        for addr in self.receiveServer.getOSCAddressSpace():\n",
    "            print addr\n",
    "            \n",
    "    def start(self):\n",
    "        # Start OSCServer\n",
    "        print \"\\nStarting OSCServer.\"\n",
    "        self.emorating_oscServer = threading.Thread(target = self.receiveServer.serve_forever)\n",
    "        self.emorating_oscServer.start()\n",
    "        print \"\\nOSCServer established.\"\n",
    "        \n",
    "    def stop(self):\n",
    "        # Close the OSC server\n",
    "        print \"\\nClosing OSCServer.\"\n",
    "        self.receiveServer.close()\n",
    "        print \"Waiting for Server-thread to finish\"\n",
    "        try:\n",
    "            self.emorating_oscServer.join() ##!!!\n",
    "            print \"Done\"\n",
    "        except AttributeError:\n",
    "            print AttributeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.70.148.55\n",
      "Server Created.\n",
      "('129.70.148.55', 8022)\n",
      "OSCServer v0.3.5b-5294 listening on osc://ip-129-70-148-55.wlan.dyn.cit-ec.net:8022\n",
      "('129.70.148.55', 8022)\n",
      "/next\n",
      "/print\n",
      "default\n",
      "/init\n",
      "/info\n",
      "/play\n",
      "/emo\n",
      "/error\n",
      "/logChange\n",
      "/degree\n",
      "/save\n",
      "\n",
      "Starting OSCServer.\n",
      "\n",
      "OSCServer established.\n",
      "next sound\n",
      "1\n",
      "next sound\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ipAddr = socket.gethostbyname(socket.getfqdn())\n",
    "print ipAddr\n",
    "init_receiver = Rating_receiver (ip = ipAddr, port = 8022,num_emotion = 9, num_degree = 4)\n",
    "init_receiver.spawn()\n",
    "init_receiver.add_handler()\n",
    "init_receiver.print_registered_func()\n",
    "init_receiver.reset_settings()\n",
    "init_receiver.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    init_receiver.stop()\n",
    "    rating_receiver.stop()\n",
    "except:\n",
    "    print \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load all data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas\n",
    "def parselist(s):\n",
    "    return array([ float(el) for el in s.translate(None, \"[]\").split(\",\") ], dtype='float64')\n",
    "\n",
    "converterdict = {'parvec': parselist};\n",
    "\n",
    "# load all data files of pattern into dataframe\n",
    "for i, fname in enumerate(glob.glob(\"../data/*.csv\")):\n",
    "    print fname\n",
    "    df = pandas.read_csv(fname, converters=converterdict)\n",
    "    if(i==0): \n",
    "        da = df\n",
    "    else: \n",
    "        da = da.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. extract all optimization endpoints and play them in a series\n",
    "(can now be done easier since I added logging for the submit button... to be updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# play all sounds for a given emtion\n",
    "# soundmodel = 'vocal'\n",
    "dsel = da[(da['submit']==1) & (da['target']=='disgusted') & (da['snd']==soundmodel)]\n",
    "\n",
    "for el in dsel.iterrows():\n",
    "    parvec = el[1]['parvec']\n",
    "    print el[1]['uid']\n",
    "    playevent(soundmodel, parvec)\n",
    "    time.sleep(1.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# play center of mass of all emotion-assigned samples\n",
    "targets = ['happy', 'surprised', 'angry', 'disgusted', 'sad', 'calm']\n",
    "soundmodel = \"vocal\"\n",
    "for t in targets:\n",
    "    print t\n",
    "    dsel = da[(da['submit']==1) & (da['target']==t) & (da['snd']==soundmodel)]\n",
    "    print dsel\n",
    "    vt = mean(dsel['parvec']) \n",
    "    print vt\n",
    "    playevent(soundmodel, vt)\n",
    "    time.sleep(1.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. interpolation experiment: play series of sounds between prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need a function to convert a array of arrays into a regular 2D array\n",
    "def aoa_2d_array(pv):\n",
    "    r = zeros((size(pv), size(pv[0])))\n",
    "    for i, el in enumerate(pv): r[i] = el\n",
    "    return r \n",
    "# test code\n",
    "#soundmodel = 'abstract'\n",
    "#aoa_2d_array(da[(da['submit']==1) & (da['snd']==soundmodel)].parvec.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array of all submitted parameter vectors\n",
    "# soundmodel='vocal'\n",
    "dtmp = da[(da['submit']==1) & (da['snd']==soundmodel) & \n",
    "          (da['uid']==1003) & (da['run']==0)].parvec.values\n",
    "pvarr = aoa_2d_array(dtmp)\n",
    "playevent(soundmodel, mean(pvarr, 0)) # mean vector of all submitted prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtmp = da[(da['submit']==1) & (da['snd']==soundmodel) & (da['uid']==1001) & (da['run']==0) ]\n",
    "# print dtmp\n",
    "par = aoa_2d_array(dtmp['parvec'].values)\n",
    "# interpolate between emotional prototypes\n",
    "for l in arange(0, 1, 0.1):\n",
    "    playevent(soundmodel, l*par[2]+(1.0-l)*par[3])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel regression-mapping for navigating between Emotionals Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assemble 6 prototype vectors\n",
    "dsel = da[(da['submit']==1) & (da['uid']==1003) & (da['snd']=='abstract') & (da['run']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = ['happy', 'surprised', 'angry', 'disgusted', 'sad', 'calm']\n",
    "pvec = dsel[:1].parvec.values[0]\n",
    "dim = len(pvec)\n",
    "Nrows = len(targets)\n",
    "pvecs = zeros((Nrows, dim))\n",
    "for i, t in enumerate(targets):\n",
    "    print i, t\n",
    "    pvecs[i]= dsel[dsel['target']==t].parvec.values[0]\n",
    "    #print t; playevent(\"jj1\", parspec, pvecs[i]); time.sleep(1.5)\n",
    "\n",
    "# kernel regression: input positions\n",
    "xvecs = zeros((Nrows, 2))\n",
    "for i in range(len(targets)):\n",
    "    xvecs[i] = [cos(2*pi*i/Nrows+0.1), sin(2*pi*i/Nrows+0.1)]\n",
    "\n",
    "def kernel(x, y, sigma=1):\n",
    "    return exp(-0.5*sum((x-y)**2)/sigma**2)\n",
    "\n",
    "def krm(xvecs, pvecs, xvec, sigma=1):\n",
    "    n=shape(xvecs)[0]\n",
    "    nom = zeros(dim)\n",
    "    den = 0\n",
    "    for i in range(n):\n",
    "        temp = kernel(xvecs[i], xvec, sigma)\n",
    "        print temp\n",
    "        nom += temp*pvecs[i]\n",
    "        den += temp\n",
    "    return nom/den\n",
    "# print xvecs[0], krm(xvecs, pvecs, xvecs[0], sigma=0.1)    \n",
    "# playevent(soundmodel, krm(xvecs, pvecs, array([-1,1]), sigma=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xvecs[:,0], xvecs[:,1], \"o\", markersize=15)\n",
    "ax.set_aspect('equal', 'datalim')\n",
    "\n",
    "wkrmsigma = widgets.FloatSlider(value=0.2, min=0, max=1, step=0.01, description='krm-sigma:')\n",
    "\n",
    "def onclick(event, verbose=False):\n",
    "    x = event.xdata; y = event.ydata;\n",
    "    if(event.button==1): #left mouse click\n",
    "        if(verbose):\n",
    "            print('(%f, %f)' % (x, y))\n",
    "        playevent(soundmodel, krm(xvecs, pvecs, array([x,y]), sigma=wkrmsigma.value))\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "display(wkrmsigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soundmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up OSC receiver for the tablet interaction. \n",
    "soundmodel = 'vocal'\n",
    "129-70-149-109\n",
    "receive_address = \"129.70.149.122\", 50010 # The receive address needs to be controlled by the tablet\n",
    "receiveSever = OSC.OSCServer(receive_address) # create a serve to receive OSC from the tablet\n",
    "receiveSever.addDefaultHandlers()\n",
    "x = 0.0\n",
    "y = 0.0\n",
    "wkrmsigma = 0.8 # later it can be control by tablet. \n",
    "\n",
    "# Need to change it to a class. \n",
    "\n",
    "def update_OSCAddress(addr,tags,stuff, source):\n",
    "    global receive_address\n",
    "    receive_address = stuff[0], int(stuff[1])\n",
    "    print \"New address:\" + stuff[0]\n",
    "    print \"New port: \"+ stuff[1]\n",
    "    \n",
    "\n",
    "\n",
    "def printing_handler(addr, tags, stuff, source):\n",
    "    global x, y, soundmodel, xvecs, pvecs, wkrmsigma\n",
    "    x = float(stuff[0])\n",
    "    y = float(stuff[1])\n",
    "    print x, y\n",
    "    playevent(soundmodel, krm(xvecs, pvecs, array([x,y]), sigma=wkrmsigma))\n",
    "\n",
    "receiveSever.addMsgHandler(\"/a\", printing_handler) # adding our function\n",
    "receiveSever.addMsgHandler(\"/addrInfo\", update_OSCAddress)\n",
    "# just checking which handlers we have added\n",
    "print \"Registered Callback-functions are :\"\n",
    "for addr in receiveSever.getOSCAddressSpace():\n",
    "    print addr\n",
    "    \n",
    "# Start OSCServer\n",
    "print \"\\nStarting OSCServer.\"\n",
    "st_oscSever = threading.Thread( target = receiveSever.serve_forever )\n",
    "st_oscSever.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the OSC server\n",
    "print \"\\nClosing OSCServer.\"\n",
    "receiveSever.close()\n",
    "print \"Waiting for Server-thread to finish\"\n",
    "st_oscSever.join() ##!!!\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "190e5d6f767b48d6aa2c1a8baadeb666": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "7ab3a63772a1423b83df05b5e7d3babd": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "bd0d4711a34a4fa18aba8805adf5ef91": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "ce8531e4ffc8434bbf55214e5eb114db": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "f6d3bb44ead443baa02adc7c5f1c1dfd": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
